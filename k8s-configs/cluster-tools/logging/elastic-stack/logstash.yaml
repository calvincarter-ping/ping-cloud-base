kind: Service
apiVersion: v1
metadata:
  name: logstash-elastic
  labels:
    app: logstash-elastic
spec:
  selector:
    app: logstash-elastic
  ports:
    - port: 9600
      name: rest
    - port: 20510
      name: enrichment-in
    - port: 20512
      name: pf-provision-in
    - port: 20513
      name: pf-system-in
    - port: 20514
      name: pf-audit-in
    - port: 20515
      name: pd-directory-in
    - port: 20516
      name: pa-system-in
    - port: 20517
      name: pa-audit-in
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: logstash-elastic
  labels:
    app: logstash-elastic
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: logstash-elastic
  labels:
    app: logstash-elastic
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: logstash-elastic
roleRef:
  kind: ClusterRole
  name: logstash-elastic
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: logstash-elastic
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubernetes-namespace-logging-logstash
  labels:
    app: logstash-elastic
data:
  logstash.conf: |
    input {
        http {
            id => "enrichment_in"
            port => 20510
            codec => "json"
            response_code => 200
            add_field => {"log_type" => "Enrichment_System_Log"}
        }
        tcp {
            id => "pf_provision_in"
            port => 20512
            add_field => {"log_type" => "PF_Provisioner_Log"}
        }
        tcp {
            id => "pf_system_in"
            port => 20513
            add_field => {"log_type" => "PF_System_Log"}
        }
        tcp {
            id => "pf_audit_in"
            port => 20514
            add_field => {"log_type" => "PF_Audit_Log"}
        }
        syslog {
          id => "pd_directory_in"
          port => 20515
          type => syslog
          add_field => {"log_type" => "PD_Access_Log"}
          codec => multiline {
            pattern => "^\s"
            what => "previous"
          }
        }
        file {
            id => "var_log"
            path => "/var/log"
        }
        file {
            id => "containers_log"
            path => "/var/lib/docker/containers"
        }
    }
    filter {
        #PROCESS PING FED AUDIT LOG
        #Log4J Pattern Matching from PF and extraction of JSON DATA from the MSG
        if([log_type] == "PF_Audit_Log"){
            grok { 
                match => { 
                    "message" => [ 
                        "\A%{SYSLOG5424PRI}%{SYSLOGTIMESTAMP:event_timestamp}%{SPACE}%{SYSLOGPROG} , %{GREEDYDATA:json_data}",
                        "\A%{SYSLOG5424PRI}%{SYSLOGTIMESTAMP:event_timestamp}%{SPACE}%{SYSLOGPROG}%{SPACE}%{GREEDYDATA:json_data}"
                        ]
                }
            } 
            #Convert the injested data into Individual Fields for elasticsearch
            json {
                source => "json_data"
            }
    
            if([json_data]){
                #Drop the original as you do not need it at this point.
                mutate {
                    remove_field => "[json_data]"
                }
    
                geoip {
                    source => "ip"
                }

                #Security Enrichments begin here, ENRICH THE IP ADDRESS DETAIL

                # translate {
                #     field => "ip"
                #     destination => "threat_intel"
                #     fallback => "No"
                #     dictionary_path => '/etc/logstash/enrichment/AlienVaultIP.yml'
                #     refresh_behaviour => "replace"
                # }
    
                # translate {
                #     field => "ip"
                #     destination => "tor_intel"
                #     fallback => "No"
                #     dictionary_path => '/etc/logstash/enrichment/TorNodes.yml'
                #     refresh_behaviour => "replace"
                # }
    
                # translate {
                #     field => "[geoip][country_name]"
                #     destination => "malicious_country"
                #     fallback => "No"
                #     dictionary_path => '/etc/logstash/enrichment/MaliciousCountries.yml'
                #     refresh_behaviour => "replace"
                # }
    
                # translate {
                #     field => "[geoip][country_name]"
                #     destination => "known_country"
                #     fallback => "No"
                #     dictionary_path => '/etc/logstash/enrichment/KnownCountries.yml'
                #     refresh_behaviour => "replace"
                # }
    
                # if([malicious_country] == "No" and [known_country] == "No"){
                #     mutate {
                #         add_field => { "suspicious_country" => "YES" }
                #     }
                # }

                # HERE SHOULD BE ADDITIONAL FILTERS WHICH RELATED TO PDO-966 SETTING UP LOGSTASH FILTERS SCOPE
            }
        }

    # PROCESS PING DIRECTORY LOGS
    # LOGS ARE SENT IN A CUSTOM FORMAT, AND THIS CONFIG MATCHES AND PARSES THEM.

        if([log_type] == "PD_Access_Log"){
          kv {
            source => "[message]"
            value_split => "="
          }

          grok {
            match => { "message" => "\A%{WORD:ldapType} %{GREEDYDATA}" }
          }

          mutate{
            gsub => [ 
                "filter", '"', ""
            ]
            gsub => [ 
                "dn", '"', ""
            ]
          }

          geoip {
            source => "requesterIP"
          }

        translate {
            field => "requesterIP"
            destination => "threat_intel"
            fallback => "No"
            dictionary_path => '/etc/logstash/enrichment/AlienVaultIP.yml'
            refresh_behaviour => "replace"
        }

        translate {
            field => "requesterIP"
            destination => "tor_intel"
            fallback => "No"
            dictionary_path => '/etc/logstash/enrichment/TorNodes.yml'
            refresh_behaviour => "replace"
        }

        translate {
            field => "[geoip][country_name]"
            destination => "malicious_country"
            fallback => "No"
            dictionary_path => '/etc/logstash/enrichment/MaliciousCountries.yml'
            refresh_behaviour => "replace"
        }

        translate {
            field => "[geoip][country_name]"
            destination => "known_country"
            fallback => "No"
            dictionary_path => '/etc/logstash/enrichment/KnownCountries.yml'
            refresh_behaviour => "replace"
        }

        if([malicious_country] == "No" and [known_country] == "No"){
            mutate {
                add_field => { "suspicious_country" => "YES" }
            }
        }

        mutate {
            remove_field => "[message]"
            remove_field => "[tags]"
        }
    }
        # PROCESS PING FED SYSTEM LOG
        # USING LOG4J's ability to output in JSON limits the amount of processing you have to do besides splitting up JSON.
    
        if([log_type] == "PF_System_Log"){
            grok { 
                match => { 
                    "message" => [ 
                        "\A%{SYSLOG5424PRI}%{SYSLOGTIMESTAMP:event_timestamp}%{SPACE}%{SYSLOGPROG} , %{GREEDYDATA:json_data}",
                        "\A%{SYSLOG5424PRI}%{SYSLOGTIMESTAMP:event_timestamp}%{SPACE}%{SYSLOGPROG}%{SPACE}%{GREEDYDATA:json_data}"
                        ]
                }
            } 
            json {
                source => "json_data"
            }
    
            if([json_data]){
                mutate {
                    remove_field => "[json_data]"
                }
            }   
        }
    }
    output {
        elasticsearch {
            index => "logstash_%{+YYYY.MM.dd}"
            hosts => "${LOGSTASH_ELASTICSEARCH_SCHEME}://${LOGSTASH_ELASTICSEARCH_HOST}:${LOGSTASH_ELASTICSEARCH_PORT}"
        }
        if([log_type] == "Enrichment_System_Log"){
          elasticsearch {
              id => "enrichment_out"
              index => "enrichment_out_%{+YYYY.MM.dd}"
              hosts => "${LOGSTASH_ELASTICSEARCH_SCHEME}://${LOGSTASH_ELASTICSEARCH_HOST}:${LOGSTASH_ELASTICSEARCH_PORT}"
          }
        }
        if([log_type] == "PF_Provisioner_Log"){
          elasticsearch {
              id => "pf_provision_out"
              index => "pf_provision_out_%{+YYYY.MM.dd}"
              hosts => "${LOGSTASH_ELASTICSEARCH_SCHEME}://${LOGSTASH_ELASTICSEARCH_HOST}:${LOGSTASH_ELASTICSEARCH_PORT}"
          }
        }
        if([log_type] == "PF_Audit_Log"){
          elasticsearch {
              id => "pf_audit_out"
              index => "pf_audit_out_%{+YYYY.MM.dd}"
              hosts => "${LOGSTASH_ELASTICSEARCH_SCHEME}://${LOGSTASH_ELASTICSEARCH_HOST}:${LOGSTASH_ELASTICSEARCH_PORT}"
          }
        }
        if([log_type] == "PF_System_Log"){
          elasticsearch {
              id => "pf_system_out"
              index => "pf_system_out_%{+YYYY.MM.dd}"
              hosts => "${LOGSTASH_ELASTICSEARCH_SCHEME}://${LOGSTASH_ELASTICSEARCH_HOST}:${LOGSTASH_ELASTICSEARCH_PORT}"
          }
        }
        if([log_type] == "PD_Access_Log"){
          elasticsearch {
            id => "pd_out"
            index => "pd_out_%{+YYYY.MM.dd}"
            hosts => "${LOGSTASH_ELASTICSEARCH_SCHEME}://${LOGSTASH_ELASTICSEARCH_HOST}:${LOGSTASH_ELASTICSEARCH_PORT}"
          }
        }
        if([log_type] == "PD_Failed_Ops"){
          elasticsearch {
            id => "pd_failed_ops_out"
            index => "pd_failed_ops_out_%{+YYYY.MM.dd}"
            hosts => "${LOGSTASH_ELASTICSEARCH_SCHEME}://${LOGSTASH_ELASTICSEARCH_HOST}:${LOGSTASH_ELASTICSEARCH_PORT}"
          }
        }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: logstash-elastic
  labels:
    app: logstash-elastic
spec:
  selector:
    matchLabels:
      app: logstash-elastic
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app: logstash-elastic
    spec:
      serviceAccount: logstash-elastic
      # tolerations:
      # - key: node-role.kubernetes.io/master
      #   effect: NoSchedule
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
      - name: logstash
        image: logstash:7.6.2
        env:
          - name:  LOGSTASH_ELASTICSEARCH_HOST
            value: "elasticsearch"
          - name:  LOGSTASH_ELASTICSEARCH_PORT
            value: "9200"
          - name: LOGSTASH_ELASTICSEARCH_SCHEME
            value: "http"
          # - name: LOGSTASH_ELASTICSEARCH_USER
          #   value: "elastic"
          # - name: LOGSTASH_ELASTICSEARCH_PASSWORD
          #   value: PASSWORD
          - name: LS_JAVA_OPTS
            value: "-Xmx1g -Xms1g"
          - name: CONFIG_RELOAD_AUTOMATIC
            value: "true"
          - name: CONFIG_RELOAD_INTERVAL
            value: "5s"
          - name: LOG_FORMAT
            value: "json"
          - name: LOG_LEVEL
            value: "info"
        resources:
          limits:
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 1Gi
        ports:
          - containerPort: 9600
            name: rest
            protocol: TCP
          - containerPort: 20510
            name: enrichment-in
            protocol: TCP
          - containerPort: 20512
            name: pf-provision-in
            protocol: TCP
          - containerPort: 20513
            name: pf-system-in
            protocol: TCP
          - containerPort: 20514
            name: pf-audit-in
            protocol: TCP
          - containerPort: 20515
            name: pd-directory-in
            protocol: TCP
          - containerPort: 20516
            name: pa-system-in
            protocol: TCP
          - containerPort: 20517
            name: pa-audit-in
            protocol: TCP
        volumeMounts:
        - name: kubernetes-namespace-logging-logstash
          mountPath: /usr/share/logstash/pipeline
          readOnly: true
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: enrichment-volume
          mountPath: /etc/logstash/enrichment
          readOnly: true
      terminationGracePeriodSeconds: 30
      volumes:
      - name: kubernetes-namespace-logging-logstash
        configMap:
          name: kubernetes-namespace-logging-logstash
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: enrichment-volume
        nfs:
          # HARDCODED VALUE! SHOULD BE CHANGED TO DYNAMIC!
          # server: fs-c2e4d068.efs.${REGION}.amazonaws.com
          server: ${EFS_FILESYSTEM_ID}.efs.${REGION}.amazonaws.com
          path: /
