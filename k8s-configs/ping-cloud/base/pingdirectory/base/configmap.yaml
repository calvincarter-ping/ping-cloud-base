apiVersion: v1
kind: ConfigMap
metadata:
  name: pingdirectory-init
data:
  init.sh: |-
    #!/bin/sh -x

    #--- Wait for services if there are any dependent services we must wait on --- #
    if test ! -z "${WAIT_FOR_SERVICES}"; then
      for SERVICE in "${WAIT_FOR_SERVICES}"; do
        until nslookup "${SERVICE}"; do
          echo "Waiting for service ${SERVICE}"
          sleep 2
        done
      done
    fi

    #--- Sleep for the configured initial delay seconds ---#
    SLEEP_SECONDS=${INITIAL_DELAY_SECONDS:-0}
    sleep ${SLEEP_SECONDS}

    #--- Copy SSH configuration files ---#
    test -f /known_hosts && cp /known_hosts /.ssh
    test -f /id_rsa && cp /id_rsa /.ssh

    # Install kubectl
    echo "Installing kubectl"
    curl https://storage.googleapis.com/kubernetes-release/release/v1.15.0/bin/linux/amd64/kubectl -o /data/kubectl
    chmod +x /data/kubectl

    #--- Generate a dummy topology JSON file so the hook that generates it in the image is not triggered ---#
    TOPOLOGY_FILE=/data/topology.json
    cat <<EOF > "${TOPOLOGY_FILE}"
    {
          "serverInstances" : []
    }
    EOF

    exit 0

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: pingdirectory-post-start
data:
  80-post-start.sh: |-
    #!/bin/sh -x

    . "${HOOKS_DIR}/pingcommon.lib.sh"

    test -f "${STAGING_DIR}/env_vars" && . "${STAGING_DIR}/env_vars"
    test -f "${HOOKS_DIR}/pingdirectory.lib.sh" && . "${HOOKS_DIR}/pingdirectory.lib.sh"

    echo "Starting post-start hook"

    echo "Running ldapsearch test on this container (${HOSTNAME})"
    waitUntilLdapUp "localhost" "${LDAPS_PORT}" ""

    echo "Changing the cluster name to ${HOSTNAME}"
    dsconfig --no-prompt \
      --useSSL --trustAll \
      --hostname "${HOSTNAME}" --port "${LDAPS_PORT}" \
      set-server-instance-prop \
      --instance-name "${HOSTNAME}" \
      --set cluster-name:"${HOSTNAME}"

    # --- NOTE ---
    # This assumes that data initialization is only required once for the initial data in the server profile.
    # Subsequent initialization of data will be performed externally after populating one of the servers using data
    # sync or some other mechanism, like import-ldif, followed by dsreplication initialize-all. This assumption may be
    # different for each customer, but the script may be easily adjusted as appropriate for the customer's use case.

    SHORT_HOST_NAME=$(hostname)
    ORDINAL=$(echo ${SHORT_HOST_NAME##*-})
    echo "Pod ordinal: ${ORDINAL}"

    REPL_SETUP_MARKER_FILE=/opt/out/instance/config/repl-setup

    if test ${ORDINAL} -eq 0; then
      echo "${USER_BASE_DN}" >> "${REPL_SETUP_MARKER_FILE}"

      # The request control allows encoded passwords, which is always required for topology admin users
      # ldapmodify allows a --passwordUpdateBehavior allow-pre-encoded-password=true to do the same
      echo "Changing admin user password, if necessary"
      ldappasswordmodify \
        --authzID "dn:cn=${ADMIN_USER_NAME}" \
        --newPasswordFile "${ADMIN_USER_PASSWORD_FILE}" \
        --control '1.3.6.1.4.1.30221.2.5.51:true::MAOBAf8='
      pwdModStatus=$?
      echo "Password reset for user ${ADMIN_USER_NAME} status: ${pwdModStatus}"

      # The following exit codes are acceptable
      # 0 -> success
      # 32 -> user does not exist (e.g. first run, so replication has not been enabled)
      # 53 -> old and new passwords are the same
      if test ${pwdModStatus} -ne 0 && test ${pwdModStatus} -ne 32 && test ${pwdModStatus} -ne 53; then
        exit ${pwdModStatus}
      fi

      exit 0
    fi

    echo "Checking if replication is already set up on ${HOSTNAME}"
    if grep -q "${USER_BASE_DN}" "${REPL_SETUP_MARKER_FILE}" 2> /dev/null; then
      echo "Replication is already set up on ${HOSTNAME} for ${USER_BASE_DN}"
      exit 0
    fi

    DOMAIN_NAME=$(hostname -f | cut -d'.' -f2-)
    SRC_HOST="${K8S_STATEFUL_SET_NAME}-0.${DOMAIN_NAME}"

    echo "Running dsreplication enable"
    dsreplication enable \
      --retryTimeoutSeconds ${RETRY_TIMEOUT_SECONDS} \
      --trustAll \
      --host1 "${SRC_HOST}" --port1 "${LDAPS_PORT}" --useSSL1 \
      --bindDN1 "${ROOT_USER_DN}" --bindPasswordFile1 "${ROOT_USER_PASSWORD_FILE}" \
      --host2 "${HOSTNAME}" --port2 "${LDAPS_PORT}" --useSSL2 \
      --bindDN2 "${ROOT_USER_DN}" --bindPasswordFile2 "${ROOT_USER_PASSWORD_FILE}" \
      --replicationPort2 "${REPLICATION_PORT}" \
      --adminUID "${ADMIN_USER_NAME}" --adminPasswordFile "${ADMIN_USER_PASSWORD_FILE}" \
      --no-prompt --ignoreWarnings \
      --baseDN "${USER_BASE_DN}" \
      --noSchemaReplication \
      --enableDebug --globalDebugLevel verbose

    _replEnableResult=$?
    echo "Replication enable for ${HOSTNAME} result=${_replEnableResult}"

    if test ${_replEnableResult} -eq 5; then
      echo "Replication is already enabled for ${USER_BASE_DN} either directly or through a parent base DN"
      echo "${USER_BASE_DN}" >> "${REPL_SETUP_MARKER_FILE}"
      exit 0
    fi

    if test ${_replEnableResult} -ne 0; then
      echo "Not running dsreplication initialize since enable failed with a non-successful return code"
      exit ${_replEnableResult}
    fi

    echo "Running dsreplication initialize"
    dsreplication initialize \
      --retryTimeoutSeconds ${RETRY_TIMEOUT_SECONDS} \
      --trustAll \
      --hostSource "${SRC_HOST}" --portSource ${LDAPS_PORT} --useSSLSource \
      --hostDestination "${HOSTNAME}" --portDestination ${LDAPS_PORT} --useSSLDestination \
      --baseDN "${USER_BASE_DN}" \
      --adminUID "${ADMIN_USER_NAME}" \
      --adminPasswordFile "${ADMIN_USER_PASSWORD_FILE}" \
      --no-prompt \
      --enableDebug \
      --globalDebugLevel verbose

    _replInitResult=$?
    echo "Replication initialize for ${HOSTNAME} result=${_replInitResult}"

    test ${_replInitResult} -eq 0 && echo "${USER_BASE_DN}" >> "${REPL_SETUP_MARKER_FILE}"
    exit ${_replInitResult}

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: pingdirectory-ready
data:
  readiness.sh: |-
    #!/bin/sh -x

    # Verify that server is responsive on its LDAP secure port
    echo "Readiness probe - verifying root DSE access"
    /opt/liveness.sh || exit 1

    # Verify that replication is set up
    echo "Readiness probe - verifying replication is set up"
    REPL_SETUP_MARKER_FILE=/opt/out/instance/config/repl-setup
    grep -q "${USER_BASE_DN}" "${REPL_SETUP_MARKER_FILE}" 2> /dev/null && exit 0 || exit 1

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: pingdirectory-pre-stop
data:
  pre-stop.sh: |-
    #!/bin/sh -x

    echo "Starting pre-stop hook"

    SHORT_HOST_NAME=$(hostname)
    ORDINAL=$(echo ${SHORT_HOST_NAME##*-})
    echo "Pod ordinal: ${ORDINAL}"

    NUM_REPLICAS=$(kubectl get statefulset "${K8S_STATEFUL_SET_NAME}" -o jsonpath='{.spec.replicas}')
    echo "Number of replicas: ${NUM_REPLICAS}"

    if test ${ORDINAL} -lt ${NUM_REPLICAS}; then
      echo "Not removing server since it is still in the topology"
      exit 0
    fi

    echo "Gettting instance name from config"
    INSTANCE_NAME=$(dsconfig --no-prompt \
      --useSSL --trustAll \
      --hostname "${HOSTNAME}" --port "${LDAPS_PORT}" \
      get-global-configuration-prop \
      --property instance-name \
      --script-friendly |
      awk '{ print $2 }')

    echo "Removing ${HOSTNAME} (instance name: ${INSTANCE_NAME}) from the topology"
    remove-defunct-server --no-prompt \
      --serverInstanceName "${INSTANCE_NAME}" \
      --retryTimeoutSeconds ${RETRY_TIMEOUT_SECONDS} \
      --ignoreOnline \
      --bindDN "${ROOT_USER_DN}" \
      --bindPasswordFile "${ROOT_USER_PASSWORD_FILE}" \
      --enableDebug --globalDebugLevel verbose
    echo "Server removal exited with return code: ${?}"

    REPL_SETUP_MARKER_FILE=/opt/out/instance/config/repl-setup
    echo "Removing ${REPL_SETUP_MARKER_FILE} marker file"
    rm -f "${REPL_SETUP_MARKER_FILE}"

---

# Mappings for PingDirectory metrics sent to the statsd-exporter, which Prometheus will scrape
# See https://github.com/prometheus/statsd_exporter
apiVersion: v1
kind: ConfigMap
metadata:
  name: pingdirectory-statsd-mapping
data:
  pingdirectory-statsd-mapping.yml: |-
    mappings:
        # operation response time and throughput
      - match: "*.*.response-time"
        name: "response_time"
        labels:
          operation: "$2"
      - match: "*.*.throughput"
        name: "throughput"
        labels:
          operation: "$2"
        # connection handler metrics
      - match: "*.*.*.*.ldap-conn-handler-bytes-read"
        name: "LDAP_connection_handler_bytes_read"
        labels:
          port: "$4"
      - match: "*.*.*.*.ldap-conn-handler-bytes-written"
        name: "LDAP_connection_handler_bytes_written"
        labels:
          port: "$4"
      - match: "*.*.*.*.ldap-conn-handler-messages-read"
        name: "LDAP_connection_handler_messages_read"
        labels:
          port: "$4"
      - match: "*.*.*.*.ldap-conn-handler-messages-written"
        name: "LDAP_connection_handler_messages_written"
        labels:
          port: "$4"
      - match: "*.*.*.*.ldap-conn-handler-search-requests"
        name: "LDAP_connection_handler_search_requests"
        labels:
          port: "$4"
      - match: "*.*.*.*.ldap-conn-handler-search-entries-returned"
        name: "LDAP_connection_handler_search_entries_returned"
        labels:
          port: "$4"
        # backend metrics
      - match: "*.backend-entry-count"
        name: "backend_entry_count"
        labels:
          backendID: "$1"
      - match: "*.backend-db-cache-percent-full"
        name: "backend_db_cache_percent_full"
        labels:
          backendID: "$1"
      - match: "*.backend-size-on-disk"
        name: "backend_size_on_disk"
        labels:
          backendID: "$1"
      - match: "*.backend-active-cleaner-threads"
        name: "backend_active_cleaner_threads"
        labels:
          backendID: "$1"
      - match: "*.backend-cleaner-backlog"
        name: "backend_cleaner_backlog"
        labels:
          backendID: "$1"
      - match: "*.backend-nodes-evicted"
        name: "backend_nodes_evicted"
        labels:
          backendID: "$1"
      - match: "*.backend-checkpoints"
        name: "backend_checkpoints"
        labels:
          backendID: "$1"
      - match: "*.backend-avg-checkpoint-duration"
        name: "backend_avg_checkpoint_duration"
        labels:
          backendID: "$1"
      - match: "*.backend-time-since-last-checkpoint"
        name: "backend_time_since_last_checkpoint"
        labels:
          backendID: "$1"
      - match: "*.backend-new-db-logs"
        name: "backend_new_db_logs"
        labels:
          backendID: "$1"
      - match: "*.backend-random-reads"
        name: "backend_random_reads"
        labels:
          backendID: "$1"
      - match: "*.backend-random-writes"
        name: "backend_random_writes"
        labels:
          backendID: "$1"
      - match: "*.backend-sequential-reads"
        name: "backend_sequential_reads"
        labels:
          backendID: "$1"
      - match: "*.backend-sequential-writes"
        name: "backend_sequential_writes"
        labels:
          backendID: "$1"
        # entry cache metrics
      - match: "*.entry-cache-hit-ratio"
        name: "entry_cache_hit_ratio"
        labels:
          entryCache: "$1"
      - match: "*.entry-cache-hit-count"
        name: "entry_cache_hit_count"
        labels:
          entryCache: "$1"
      - match: "*.entry-cache-attempts"
        name: "entry_cache_attempts"
        labels:
          entryCache: "$1"
      - match: "*.entry-cache-add-or-update"
        name: "entry_cache_add_or_update"
        labels:
          entryCache: "$1"
      - match: "*.entry-cache-size"
        name: "entry_cache_size"
        labels:
          entryCache: "$1"
      - match: "*.entry-cache-pct-full"
        name: "entry_cache_pct_full"
        labels:
          entryCache: "$1"
        # changelog metrics?
      - match: "changelog.*"
        name: "$1"
        lables:
          backendID: "changelog"
        # GC metrics
      - match: "*.*.*.garbage-collections"
        name: "garbage_collections"
        labels:
          gcType: "$1"
          size: "$2"
          cause: "$3"
      - match: "*.*.*.garbage-collection-duration"
        name: "garbage_collection_duration"
        labels:
          gcType: "$1"
          size: "$2"
          cause: "$3"
      - match: "*.garbage-collection-live-mbytes"
        name: "garbage_collection_live_megabytes"
        labels:
          region: "$1"