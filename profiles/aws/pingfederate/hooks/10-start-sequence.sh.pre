#!/usr/bin/env sh

${VERBOSE} && set -x

. "${HOOKS_DIR}/pingcommon.lib.sh"
. "${HOOKS_DIR}/utils.lib.sh"

run_hook "10-download-artifact.sh"

IKs="pf-jwt-token-translator-1.1.1.2.jar \
  opentoken-adapter-2.7.jar \
  pf-pcv-pone-52.137.jar \
  pf-pingid-idp-adapter-2.11.1.jar \
  pf-pingid-quickconnection-1.1.1.jar \
  pf-pingone-datastore-2.2.2.jar \
  pf-pingone-mfa-adapter-1.3.2.jar \
  pf-pingone-pcv-2.2.2.jar \
  pf-pingone-quickconnection-2.2.2.jar \
  pf-pingone-risk-management-adapter-1.1.jar \
  pf-referenceid-adapter-2.0.3.jar \
  PingIDRadiusPCV-2.9.1.jar \
  x509-certificate-adapter-1.3.1.jar"

echo "calvintest"

for ik in ${IKs}
do
  echo ${ik}
  find /opt/out/instance -name *${ik}*
done

if ! [ -z "${OPERATIONAL_MODE}" ] &&  [ "${OPERATIONAL_MODE}" != "CLUSTERED_ENGINE" ]; then
   # See if data backup is present on s3 - we check this even for the startup case so updates of existing customers that
   # had been using Kubernetes Deployment objects for the PingFederate admin still function correctly.
   run_hook "90-restore-backup-s3.sh"
   run_hook "10-setup-master-key.sh"
   run_hook "10-cleanup-work-directory.sh"
fi

if ! [ -z "${OPERATIONAL_MODE}" ] &&  [ "${OPERATIONAL_MODE}" = "CLUSTERED_ENGINE" ]; then
   run_hook "10-get-master-key.sh"
fi

beluga_log "pre-start: configure the PF cluster"

run_hook "100-tail-logs.sh"
